{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"800px\" src=\"../fidle/img/00-Fidle-header-01.svg\"></img>\n",
    "\n",
    "\n",
    "## Mise a jour du catalog des notebooks et des READMEs\n",
    " - Génération du **catalog des notebooks** : [./logs/catalog.json](./logs/catalog.json)  \n",
    "   Ce fichier comporte une liste détaillée de tous les notebooks et scripts.\n",
    "   \n",
    "   \n",
    " - Génération automatique de la table des matières et mise à jour des **README**\n",
    "     - [README.md](../README.md)\n",
    "     - [README.ipynb](../README.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Load modules and init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from IPython.display import display,Image,Markdown,HTML\n",
    "import re\n",
    "import sys, os, glob\n",
    "import datetime, time\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.append('..')\n",
    "import fidle.pwk as pwk\n",
    "import fidle.config as config\n",
    "import fidle.cookindex as cookindex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - List of folders containing notebooks to be indexed :\n",
    "Order wil be index order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories_to_index = {'LinearReg':'Linear and logistic regression', \n",
    "                        'IRIS':'Perceptron Model 1957', \n",
    "                        'BHPD':'Basic regression using DNN',\n",
    "                        'MNIST':'Basic classification using a DNN',\n",
    "                        'GTSRB':'Images classification with Convolutional Neural Networks (CNN)',\n",
    "                        'IMDB':'Sentiment analysis with word embedding',\n",
    "                        'SYNOP':'Time series with Recurrent Neural Network (RNN)',\n",
    "                        'AE':'Unsupervised learning with an autoencoder neural network (AE)',\n",
    "                        'VAE':'Generative network with Variational Autoencoder (VAE)',\n",
    "                        'Misc':'Miscellaneous'\n",
    "                        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Catalog of notebooks\n",
    "### 3.1 - Build catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read :  LinearReg/01-Linear-Regression.ipynb\n",
      "Read :  LinearReg/02-Gradient-descent.ipynb\n",
      "Read :  LinearReg/03-Polynomial-Regression.ipynb\n",
      "Read :  LinearReg/04-Logistic-Regression.ipynb\n",
      "Read :  IRIS/01-Simple-Perceptron.ipynb\n",
      "Read :  BHPD/01-DNN-Regression.ipynb\n",
      "Read :  BHPD/02-DNN-Regression-Premium.ipynb\n",
      "Read :  MNIST/01-DNN-MNIST.ipynb\n",
      "Read :  MNIST/02-CNN-MNIST.ipynb\n",
      "Read :  GTSRB/01-Preparation-of-data.ipynb\n",
      "Read :  GTSRB/02-First-convolutions.ipynb\n",
      "Read :  GTSRB/03-Tracking-and-visualizing.ipynb\n",
      "Read :  GTSRB/04-Data-augmentation.ipynb\n",
      "Read :  GTSRB/05-Full-convolutions.ipynb\n",
      "Read :  GTSRB/06-Notebook-as-a-batch.ipynb\n",
      "Read :  GTSRB/07-Show-report.ipynb\n",
      "Read :  IMDB/01-Embedding-Keras.ipynb\n",
      "Read :  IMDB/02-Prediction.ipynb\n",
      "Read :  IMDB/03-LSTM-Keras.ipynb\n",
      "Read :  SYNOP/01-Preparation-of-data.ipynb\n",
      "Read :  SYNOP/02-First-predictions.ipynb\n",
      "Read :  SYNOP/03-12h-predictions.ipynb\n",
      "Read :  AE/01-AE-with-MNIST.ipynb\n",
      "Read :  AE/02-AE-with-MNIST-post.ipynb\n",
      "Read :  VAE/01-VAE-with-MNIST.ipynb\n",
      "Read :  VAE/02-VAE-with-MNIST-post.ipynb\n",
      "Read :  VAE/05-About-CelebA.ipynb\n",
      "Read :  VAE/06-Prepare-CelebA-datasets.ipynb\n",
      "Read :  VAE/07-Check-CelebA.ipynb\n",
      "Read :  VAE/08-VAE-with-CelebA.ipynb\n",
      "Read :  VAE/09-VAE-with-CelebA-post.ipynb\n",
      "Read :  Misc/Activation-Functions.ipynb\n",
      "Read :  Misc/Numpy.ipynb\n",
      "Read :  Misc/Using-Tensorboard.ipynb\n",
      "Catalog saved as ../fidle/logs/catalog.json\n",
      "Entries :  37\n"
     ]
    }
   ],
   "source": [
    "# ---- Get the notebook list\n",
    "#\n",
    "files_list = cookindex.get_files(directories_to_index.keys())\n",
    "\n",
    "# ---- Get a detailled catalog for this list\n",
    "#\n",
    "catalog = cookindex.get_catalog(files_list)\n",
    "\n",
    "with open(config.CATALOG_FILE,'wt') as fp:\n",
    "    json.dump(catalog,fp,indent=4)\n",
    "    print(f'Catalog saved as {config.CATALOG_FILE}')\n",
    "    print('Entries : ',len(catalog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 build index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Index is :**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Linear and logistic regression\n",
       "- **[LINR1](LinearReg/01-Linear-Regression.ipynb)** - [Linear regression with direct resolution](LinearReg/01-Linear-Regression.ipynb)  \n",
       "Low-level implementation, using numpy, of a direct resolution for a linear regression\n",
       "- **[GRAD1](LinearReg/02-Gradient-descent.ipynb)** - [Linear regression with gradient descent](LinearReg/02-Gradient-descent.ipynb)  \n",
       "Low level implementation of a solution by gradient descent. Basic and stochastic approach.\n",
       "- **[POLR1](LinearReg/03-Polynomial-Regression.ipynb)** - [Complexity Syndrome](LinearReg/03-Polynomial-Regression.ipynb)  \n",
       "Illustration of the problem of complexity with the polynomial regression\n",
       "- **[LOGR1](LinearReg/04-Logistic-Regression.ipynb)** - [Logistic regression](LinearReg/04-Logistic-Regression.ipynb)  \n",
       "Simple example of logistic regression with a sklearn solution\n",
       "\n",
       "### Perceptron Model 1957\n",
       "- **[PER57](IRIS/01-Simple-Perceptron.ipynb)** - [Perceptron Model 1957](IRIS/01-Simple-Perceptron.ipynb)  \n",
       "Example of use of a Perceptron, with sklearn and IRIS dataset of 1936 !\n",
       "\n",
       "### Basic regression using DNN\n",
       "- **[BHPD1](BHPD/01-DNN-Regression.ipynb)** - [Regression with a Dense Network (DNN)](BHPD/01-DNN-Regression.ipynb)  \n",
       "Simple example of a regression with the dataset Boston Housing Prices Dataset (BHPD)\n",
       "- **[BHPD2](BHPD/02-DNN-Regression-Premium.ipynb)** - [Regression with a Dense Network (DNN) - Advanced code](BHPD/02-DNN-Regression-Premium.ipynb)  \n",
       "A more advanced implementation of the precedent example\n",
       "\n",
       "### Basic classification using a DNN\n",
       "- **[MNIST1](MNIST/01-DNN-MNIST.ipynb)** - [Simple classification with DNN](MNIST/01-DNN-MNIST.ipynb)  \n",
       "An example of classification using a dense neural network for the famous MNIST dataset\n",
       "- **[MNIST2](MNIST/02-CNN-MNIST.ipynb)** - [Simple classification with CNN](MNIST/02-CNN-MNIST.ipynb)  \n",
       "An example of classification using a convolutional neural network for the famous MNIST dataset\n",
       "\n",
       "### Images classification with Convolutional Neural Networks (CNN)\n",
       "- **[GTSRB1](GTSRB/01-Preparation-of-data.ipynb)** - [Dataset analysis and preparation](GTSRB/01-Preparation-of-data.ipynb)  \n",
       "Episode 1 : Analysis of the GTSRB dataset and creation of an enhanced dataset\n",
       "- **[GTSRB2](GTSRB/02-First-convolutions.ipynb)** - [First convolutions](GTSRB/02-First-convolutions.ipynb)  \n",
       "Episode 2 : First convolutions and first classification of our traffic signs\n",
       "- **[GTSRB3](GTSRB/03-Tracking-and-visualizing.ipynb)** - [Training monitoring](GTSRB/03-Tracking-and-visualizing.ipynb)  \n",
       "Episode 3 : Monitoring, analysis and check points during a training session\n",
       "- **[GTSRB4](GTSRB/04-Data-augmentation.ipynb)** - [Data augmentation ](GTSRB/04-Data-augmentation.ipynb)  \n",
       "Episode 4 : Adding data by data augmentation when we lack it, to improve our results\n",
       "- **[GTSRB5](GTSRB/05-Full-convolutions.ipynb)** - [Full convolutions](GTSRB/05-Full-convolutions.ipynb)  \n",
       "Episode 5 : A lot of models, a lot of datasets and a lot of results.\n",
       "- **[GTSRB6](GTSRB/06-Notebook-as-a-batch.ipynb)** - [Full convolutions as a batch](GTSRB/06-Notebook-as-a-batch.ipynb)  \n",
       "Episode 6 : To compute bigger, use your notebook in batch mode\n",
       "- **[GTSRB7](GTSRB/07-Show-report.ipynb)** - [Batch reports](GTSRB/07-Show-report.ipynb)  \n",
       "Episode 7 : Displaying our jobs report, and the winner is...\n",
       "- **[GTSRB10](GTSRB/batch_oar.sh)** - [OAR batch script submission](GTSRB/batch_oar.sh)  \n",
       "Bash script for an OAR batch submission of an ipython code\n",
       "- **[GTSRB11](GTSRB/batch_slurm.sh)** - [SLURM batch script](GTSRB/batch_slurm.sh)  \n",
       "Bash script for a Slurm batch submission of an ipython code\n",
       "\n",
       "### Sentiment analysis with word embedding\n",
       "- **[IMDB1](IMDB/01-Embedding-Keras.ipynb)** - [Sentiment analysis with text embedding](IMDB/01-Embedding-Keras.ipynb)  \n",
       "A very classical example of word embedding with a dataset from Internet Movie Database (IMDB)\n",
       "- **[IMDB2](IMDB/02-Prediction.ipynb)** - [Reload and reuse a saved model](IMDB/02-Prediction.ipynb)  \n",
       "Retrieving a saved model to perform a sentiment analysis (movie review)\n",
       "- **[IMDB3](IMDB/03-LSTM-Keras.ipynb)** - [Sentiment analysis with a LSTM network](IMDB/03-LSTM-Keras.ipynb)  \n",
       "Still the same problem, but with a network combining embedding and LSTM\n",
       "\n",
       "### Time series with Recurrent Neural Network (RNN)\n",
       "- **[SYNOP1](SYNOP/01-Preparation-of-data.ipynb)** - [Preparation of data](SYNOP/01-Preparation-of-data.ipynb)  \n",
       "Episode 1 : Data analysis and preparation of a meteorological dataset (SYNOP)\n",
       "- **[SYNOP2](SYNOP/02-First-predictions.ipynb)** - [First predictions at 3h](SYNOP/02-First-predictions.ipynb)  \n",
       "Episode 2 : Learning session and weather prediction attempt at 3h\n",
       "- **[SYNOP3](SYNOP/03-12h-predictions.ipynb)** - [12h predictions](SYNOP/03-12h-predictions.ipynb)  \n",
       "Episode 3: Attempt to predict in a more longer term \n",
       "\n",
       "### Unsupervised learning with an autoencoder neural network (AE)\n",
       "- **[AE1](AE/01-AE-with-MNIST.ipynb)** - [Building and training an AE denoiser model](AE/01-AE-with-MNIST.ipynb)  \n",
       "Episode 1 : After construction, the model is trained with noisy data from the MNIST dataset.\n",
       "- **[AE2](AE/02-AE-with-MNIST-post.ipynb)** - [Exploring our denoiser model](AE/02-AE-with-MNIST-post.ipynb)  \n",
       "Episode 2 : Using the previously trained autoencoder to denoise data\n",
       "\n",
       "### Generative network with Variational Autoencoder (VAE)\n",
       "- **[VAE1](VAE/01-VAE-with-MNIST.ipynb)** - [First VAE, with a small dataset (MNIST)](VAE/01-VAE-with-MNIST.ipynb)  \n",
       "Construction and training of a VAE with a latent space of small dimension.\n",
       "- **[VAE2](VAE/02-VAE-with-MNIST-post.ipynb)** - [Analysis of the associated latent space](VAE/02-VAE-with-MNIST-post.ipynb)  \n",
       "Visualization and analysis of the VAE's latent space\n",
       "- **[VAE5](VAE/05-About-CelebA.ipynb)** - [Another game play : About the CelebA dataset](VAE/05-About-CelebA.ipynb)  \n",
       "Episode 1 : Presentation of the CelebA dataset and problems related to its size\n",
       "- **[VAE6](VAE/06-Prepare-CelebA-datasets.ipynb)** - [Generation of a clustered dataset](VAE/06-Prepare-CelebA-datasets.ipynb)  \n",
       "Episode 2 : Analysis of the CelebA dataset and creation of an clustered and usable dataset\n",
       "- **[VAE7](VAE/07-Check-CelebA.ipynb)** - [Checking the clustered dataset](VAE/07-Check-CelebA.ipynb)  \n",
       "Episode : 3 Clustered dataset verification and testing of our datagenerator\n",
       "- **[VAE8](VAE/08-VAE-with-CelebA.ipynb)** - [Training session for our VAE](VAE/08-VAE-with-CelebA.ipynb)  \n",
       "Episode 4 : Training with our clustered datasets in notebook or batch mode\n",
       "- **[VAE9](VAE/09-VAE-with-CelebA-post.ipynb)** - [Data generation from latent space](VAE/09-VAE-with-CelebA-post.ipynb)  \n",
       "Episode 5 : Exploring latent space to generate new data\n",
       "- **[VAE10](VAE/batch_slurm.sh)** - [SLURM batch script](VAE/batch_slurm.sh)  \n",
       "Bash script for SLURM batch submission of VAE8 notebooks \n",
       "\n",
       "### Miscellaneous\n",
       "- **[ACTF1](Misc/Activation-Functions.ipynb)** - [Activation functions](Misc/Activation-Functions.ipynb)  \n",
       "Some activation functions, with their derivatives.\n",
       "- **[NP1](Misc/Numpy.ipynb)** - [A short introduction to Numpy](Misc/Numpy.ipynb)  \n",
       "Numpy is an essential tool for the Scientific Python.\n",
       "- **[TSB1](Misc/Using-Tensorboard.ipynb)** - [Tensorboard with/from Jupyter ](Misc/Using-Tensorboard.ipynb)  \n",
       "4 ways to use Tensorboard from the Jupyter environment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "styles = open('css/readme.css', \"r\").read()\n",
    "\n",
    "lines_md=[]\n",
    "lines_html=[styles]\n",
    "\n",
    "for directory,title in directories_to_index.items():\n",
    "    \n",
    "    lines_md.append(f'\\n### {title}')\n",
    "    lines_html.append( f'<div class=\"fid_section\">{title}</div>')\n",
    "    \n",
    "    entries = { k:v for k,v in catalog.items() if v['dirname']==directory }\n",
    "\n",
    "    for id, about in entries.items():\n",
    "        id          = about['id']\n",
    "        dirname     = about['dirname']\n",
    "        basename    = about['basename']\n",
    "        title       = about['title']\n",
    "        description = about['description']\n",
    "\n",
    "        link=f'{dirname}/{basename}'.replace(' ','%20')\n",
    "        md   = f'- **[{id}]({link})** - [{title}]({link})  \\n'\n",
    "        md  += f'{description}'\n",
    "        html = f\"\"\"<div class=\"fid_line\">\n",
    "                       <span class=\"fid_id\">\n",
    "                           <a href=\"{link}\">{id}</a>\n",
    "                       </span> <a href=\"{link}\">{title}</a><br>\n",
    "                       <span class=\"fid_desc\">{description}</span>\n",
    "                  </div>\n",
    "                \"\"\"\n",
    "        lines_md.append(md)\n",
    "        lines_html.append(html)\n",
    "\n",
    "index_md   = '\\n'.join(lines_md)\n",
    "index_html = '\\n'.join(lines_html)\n",
    "\n",
    "display(Markdown('**Index is :**'))\n",
    "\n",
    "display(Markdown(index_md))\n",
    "# display(HTML(index_html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Update README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md is updated.\n"
     ]
    }
   ],
   "source": [
    "# ---- Load README.md\n",
    "#\n",
    "with open('../README.md','r') as fp:\n",
    "    readme=fp.read()\n",
    "    \n",
    "# ---- Update index, version\n",
    "#\n",
    "readme = cookindex.tag('INDEX',   index_md,                readme)\n",
    "readme = cookindex.tag('VERSION', f'**{config.VERSION}**', readme)\n",
    "\n",
    "# ---- Save it\n",
    "#\n",
    "with open('../README.md','wt') as fp:\n",
    "    fp.write(readme)\n",
    "\n",
    "print('README.md is updated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - README.ipynb\n",
    "Just execute README.ipynb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ---- Load notebook\n",
    "#\n",
    "notebook = nbformat.read('../README.ipynb', nbformat.NO_CONVERT)\n",
    "\n",
    "# new_cell = nbformat.v4.new_markdown_cell(source=readme)\n",
    "# notebook.cells.append(new_cell)\n",
    "\n",
    "# ---- Execute it\n",
    "#\n",
    "ep = ExecutePreprocessor(timeout=600, kernel_name=\"python3\")\n",
    "ep.preprocess(notebook,  {'metadata': {'path': '..'}})\n",
    "\n",
    "# ---- Save it\n",
    "with open('../READMEv2.ipynb', mode=\"w\", encoding='utf-8') as fp:\n",
    "    nbformat.write(notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - More fun : Create and execute it :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus rigolo, on va fabriquer le README.ipynb et l'executer :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.ipynb built and saved\n"
     ]
    }
   ],
   "source": [
    "# ---- Create Notebook from scratch\n",
    "#\n",
    "notebook = nbformat.v4.new_notebook()\n",
    "\n",
    "# ---- Add a code cell\n",
    "#\n",
    "code = \"from IPython.display import display,Markdown\\n\"\n",
    "code+= \"display(Markdown(open('README.md', 'r').read()))\\n\"\n",
    "code+= \"#\\n\"\n",
    "code+= \"# This README is visible under Jupiter LAb ! :-)\"\n",
    "\n",
    "new_cell = nbformat.v4.new_code_cell(source=code)\n",
    "new_cell['metadata']= { \"jupyter\": { \"source_hidden\": True} }\n",
    "notebook.cells.append(new_cell)\n",
    "\n",
    "# --- Pour éviter une modification lors de l'ouverture du notebook\n",
    "#     pas génante, mais nécessite de resauvegarder le document à la fermeture...\n",
    "notebook['metadata'][\"kernelspec\"] = {\"display_name\": \"Python 3\", \"language\": \"python\", \"name\": \"python3\" }\n",
    "\n",
    "# ---- Run it\n",
    "#\n",
    "ep = ExecutePreprocessor(timeout=600, kernel_name=\"python3\")\n",
    "ep.preprocess(notebook,  {'metadata': {'path': '..'}})\n",
    "\n",
    "# ---- Save it\n",
    "#\n",
    "with open('../README.ipynb', mode=\"w\", encoding='utf-8') as fp:\n",
    "    nbformat.write(notebook, fp)\n",
    "print('README.ipynb built and saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img width=\"80px\" src=\"../fidle/img/00-Fidle-logo-01.svg\"></img>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
